<!DOCTYPE html><html lang="ko-KR"><head><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><link href="https://fonts.googleapis.com/css?family=Noto+Sans+KR:300,400,500,700|Parisienne&amp;display=swap&amp;subset=korean" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Parisienne&amp;display=swap" rel="stylesheet"/><link href="https://fastly.jsdelivr.net/gh/projectnoonnu/noonfonts_three@1.0/D2Coding.woff" rel="stylesheet"/><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta property="og:type" content="profile"/><meta property="profile:first_name" content="Jung gu"/><meta property="profile:last_name" content="Ji"/><meta property="profile:username" content="junggu.ji.dev"/><meta property="profile:gender" content="male"/><meta property="og:title" content="지중구 이력서"/><meta property="og:image" content="/resume//_next/static/images/JGJI-ae4ee6ccb074598c4d1e4ad0fcd64dd6.jpg"/><meta property="og:image:alt" content="증명 사진"/><meta property="og:image:width" content="800"/><meta property="og:image:height" content="600"/><title>지중구 이력서</title><link rel="shortcut icon" href="/resume//_next/static/images/favicon-f8d15634f8502a47fbe53edeb125d982.ico"/><link rel="preload" href="/resume/_next/static/css/2de2c7b4f1e4c2c47e77.css" as="style"/><link rel="stylesheet" href="/resume/_next/static/css/2de2c7b4f1e4c2c47e77.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/resume/_next/static/chunks/main-6c75bd467717b38043dc.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/framework.53cfa66f9846f4090096.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/f4e18d47.2a1b3f92ee167813966f.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/f6078781a05fe1bcb0902d23dbbb2662c8d200b3.9ee6b060a042bf298ef6.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/pages/_app-f70cb09c4703462ce6b2.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/a9a7754c.1e1dd1aff4d8e69ede10.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/cb1608f2.004389bbd8c6c33791ed.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/0f1ac474.6861323f142ad29f5913.js" as="script"/><link rel="preload" href="/resume/_next/static/chunks/pages/index-3ed10d6fc154e8c60c10.js" as="script"/></head><body><div id="__next"><div style="font-family:&#x27;D2Coding&#x27;;font-weight:300;word-wrap:break-word;word-break:keep-all;line-height:1.8" class="container"><div class="mt-5"><div class="row"><div class="col-sm-12 col-md-3"><div class="pb-3 text-md-right text-center"><img style="max-height:320px" class="img-fluid rounded" src="/resume//_next/static/images/JGJI-ae4ee6ccb074598c4d1e4ad0fcd64dd6.jpg" alt="Profile"/></div></div><div class="col-sm-12 col-md-9"><div class="row"><div class="text-center text-md-left col"><h1 style="color:#3c78d8">지중구<!-- --> <small>(Junggu Ji)</small></h1></div></div><div class="row"><div class="pt-3 col"><div class="pb-2 row"><div class="text-right col-1"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></div><div class="col-auto"><a href="#" target="_blank" rel="noreferrer noopener">junggu.ji.dev@gmail.com</a></div></div><div class="pb-2 row"><div class="text-right col-1"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="phone" class="svg-inline--fa fa-phone fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M493.4 24.6l-104-24c-11.3-2.6-22.9 3.3-27.5 13.9l-48 112c-4.2 9.8-1.4 21.3 6.9 28l60.6 49.6c-36 76.7-98.9 140.5-177.2 177.2l-49.6-60.6c-6.8-8.3-18.2-11.1-28-6.9l-112 48C3.9 366.5-2 378.1.6 389.4l24 104C27.1 504.2 36.7 512 48 512c256.1 0 464-207.5 464-464 0-11.2-7.7-20.9-18.6-23.4z"></path></svg></div><div class="col-auto"><span class="badge badge-light">Please contact me by email</span></div></div><div class="pb-2 row"><div class="text-right col-1"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div><div class="col-auto"><a href="https://github.com/jungguji" target="_blank" rel="noreferrer noopener">https://github.com/jungguji</a></div></div><div class="pb-2 row"><div class="text-right col-1"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="blogger-b" class="svg-inline--fa fa-blogger-b fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M446.6 222.7c-1.8-8-6.8-15.4-12.5-18.5-1.8-1-13-2.2-25-2.7-20.1-.9-22.3-1.3-28.7-5-10.1-5.9-12.8-12.3-12.9-29.5-.1-33-13.8-63.7-40.9-91.3-19.3-19.7-40.9-33-65.5-40.5-5.9-1.8-19.1-2.4-63.3-2.9-69.4-.8-84.8.6-108.4 10C45.9 59.5 14.7 96.1 3.3 142.9 1.2 151.7.7 165.8.2 246.8c-.6 101.5.1 116.4 6.4 136.5 15.6 49.6 59.9 86.3 104.4 94.3 14.8 2.7 197.3 3.3 216 .8 32.5-4.4 58-17.5 81.9-41.9 17.3-17.7 28.1-36.8 35.2-62.1 4.9-17.6 4.5-142.8 2.5-151.7zm-322.1-63.6c7.8-7.9 10-8.2 58.8-8.2 43.9 0 45.4.1 51.8 3.4 9.3 4.7 13.4 11.3 13.4 21.9 0 9.5-3.8 16.2-12.3 21.6-4.6 2.9-7.3 3.1-50.3 3.3-26.5.2-47.7-.4-50.8-1.2-16.6-4.7-22.8-28.5-10.6-40.8zm191.8 199.8l-14.9 2.4-77.5.9c-68.1.8-87.3-.4-90.9-2-7.1-3.1-13.8-11.7-14.9-19.4-1.1-7.3 2.6-17.3 8.2-22.4 7.1-6.4 10.2-6.6 97.3-6.7 89.6-.1 89.1-.1 97.6 7.8 12.1 11.3 9.5 31.2-4.9 39.4z"></path></svg></div><div class="col-auto"><a href="https://jungguji.github.io/" target="_blank" rel="noreferrer noopener">https://jungguji.github.io/</a></div></div></div></div></div></div></div><div class="mt-5"><div class="row"><div class="col-sm-12 col-md-3"><h2 style="color:#3c78d8">INTRODUCE</h2></div><div class="col-sm-12 col-md-9"><span><span>백엔드 개발자로서 대규모 트래픽 환경에서의 <strong>시스템 안정성 확보 및 성능 최적화</strong> 경험에 강점이 있습니다.</span></span><span><br/></span><span><span>AI 챗봇 서비스의 응답 속도를 <strong>수분에서 수초 이내로 개선</strong>하고, 푸시 알림 시스템 발송 시간을 <strong>90% 이상 단축</strong>하는 등 실질적인 성능 개선을 이끌었습니다.</span></span><span><br/></span><span><span><strong>Redis 분산 락을 활용한 동시성 제어</strong>(<a href="https://jungguji.github.io/2024/12/24/%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%9D%B4%EC%8A%88%EC%99%80-Redis-Redisson-%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95/" target="_blank" rel="noopener noreferrer">관련 아티클</a>), <strong>AWS SQS 기반 비동기 아키텍처 전환</strong>, <strong>JPA Entity 모듈화</strong> 등 확장성과 유지보수성을 고려한 시스템 설계를 주도했습니다.</span></span><span><br/></span><span><span><strong>테스트 코드 작성과 코드 품질 개선</strong>에 꾸준히 관심을 가지고, <strong>Fixture Monkey</strong>와 같은 도구를 활용하여 테스트 효율성을 높이는 방법을 탐구하고 공유합니다 (<a href="https://jungguji.github.io/2024/11/19/%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%BD%94%EB%93%9C-%EC%9E%91%EC%84%B1%EC%9D%84-%EB%8D%94-%EC%89%BD%EA%B2%8C-with-Fixture-Monkey/" target="_blank" rel="noopener noreferrer">관련 아티클</a>).</span></span><span><br/></span><span><span>문서화와 지식 공유를 중요하게 생각하며, <strong>기술 블로그 운영</strong> 및 팀 내 공유를 통해 함께 성장하는 것을 즐깁니다.</span></span><p class="text-right"><small>Latest Updated</small> <span class="badge badge-secondary">2025. 05. 12 (D+0)</span></p><p class="text-right" style="font-family:&#x27;Parisienne&#x27;, cursive;font-size:1.5em">Junggu Ji</p></div></div></div><div class="mt-5"><div class="row"><div class="col"><div class="pb-3 row"><div class="col"><h2 style="color:#3c78d8">EXPERIENCE</h2></div></div><div><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-9 col-md-12"><h4 style="color:gray">2023. 04 ~ 2024. 11</h4></div><div class="text-md-right text-center col-3 col-md-12"><span class="badge badge-info">1년 8개월</span></div></div></div><div class="col-sm-12 col-md-9"><h4>제네시스랩</h4><i style="color:gray">Server Back-end Developer</i><ul class="pt-3"><li>AI 기반 대화 서비스 &quot;쥬씨(ZUICY)&quot;의 메인 서버 및 분산 환경(8대) 운영/개발, 50만 가입자 트래픽 대응 아키텍처 개선</li><li>AI Agent(LLM) 톡 기능 및 선톡(먼저 메시지 보내기) 기능 신규 개발, 사용자 리텐션 10~20%p 증가 및 재참여율 40% 달성</li><li>Redis(Redisson) 분산 락 도입으로 동시성 이슈 해결, 결제/정산 시스템 데이터 무결성 확보 및 대규모 부하 테스트 검증</li><li>Spring Scheduler 이중화 및 LLM API 트래픽 분산 전략으로 일 1만건 이상 메시지 안정적 생성/발송 시스템 구축</li><li>AWS SQS 기반 비동기 아키텍처 전환, WebClient 도입 등으로 채팅 응답 속도 수분→수초 이내로 대폭 개선</li><li>기술 세미나·블로그 등 팀 내외 경험 공유로 조직 전체 기술력 향상에 기여</li><li><strong>Skill Keywords</strong><div><span style="font-weight:400" class="mr-1 badge badge-secondary">Java</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Spring Boot</span><span style="font-weight:400" class="mr-1 badge badge-secondary">GraphQL</span><span style="font-weight:400" class="mr-1 badge badge-secondary">MariaDB</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Redis</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Docker</span><span style="font-weight:400" class="mr-1 badge badge-secondary">SQS</span></div></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-9 col-md-12"><h4 style="color:gray">2021. 01 ~ 2023. 04</h4></div><div class="text-md-right text-center col-3 col-md-12"><span class="badge badge-info">2년 4개월</span></div></div></div><div class="col-sm-12 col-md-9"><h4>유모멘트</h4><i style="color:gray">Server Back-end Developer</i><ul class="pt-3"><li>Java Spring + JPA(Hibernate) 기반 &quot;웨딩의 여신&quot; 서비스 백엔드 개발 및 AWS 클라우드 운영</li><li>푸시 알림 시스템 병렬 처리·벌크 API 적용으로 19만명 대상 발송 시간 5시간→30분 이내로 90% 단축</li><li>JPA Entity 공통 모듈화 및 Nexus 배포로 코드 중복 제거, 데이터 모델 일관성·생산성 향상</li><li>Shell script 자동화, Slack 연동 모니터링 등 운영 효율화 및 장애 대응 체계 구축</li><li>레거시 서비스 개선·신규 개발, 대량 메시지 처리 등 실전 성능 최적화 경험</li><li><strong>Skill Keywords</strong><div><span style="font-weight:400" class="mr-1 badge badge-secondary">Java</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Spring</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Spring Boot</span><span style="font-weight:400" class="mr-1 badge badge-secondary">MySQL</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Hibernate</span><span style="font-weight:400" class="mr-1 badge badge-secondary">AWS</span></div></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-9 col-md-12"><h4 style="color:gray">2016. 09 ~ 2019. 06</h4></div><div class="text-md-right text-center col-3 col-md-12"><span class="badge badge-info">2년 10개월</span></div></div></div><div class="col-sm-12 col-md-9"><h4>티엔씨파트너</h4><i style="color:gray">Java Developer</i><ul class="pt-3"><li>Enovia 솔루션을 이용한 PDM / PLM 시스템 개발</li><li>Spring + Dojo + Hibernate 기반의 자체 framework를 이용한 MES 시스템 개발</li><li>Java를 이용한 SOAP WebService를 활용한 이종간 Interface 기능 개발</li><li>OODB내에 Tree구조로 저장된 Data 파싱하여 RDB에 저장하는 기능 개발</li><li><strong>Skill Keywords</strong><div><span style="font-weight:400" class="mr-1 badge badge-secondary">Java</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Enovia</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Spring</span><span style="font-weight:400" class="mr-1 badge badge-secondary">JSP</span><span style="font-weight:400" class="mr-1 badge badge-secondary">jQuery</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Oracle</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Hibernate</span><span style="font-weight:400" class="mr-1 badge badge-secondary">Mybatis</span></div></li></ul></div></div></div></div></div></div><div class="mt-5"><div class="row"><div class="col"><div class="pb-3 row"><div class="col"><h2 style="color:#3c78d8"><span>PROJECT</span></h2></div></div><div class="row"><div class="col"><div><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2024. 08 ~ 2024. 09</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>ZUICY 톡 기능용 신규 재화 시스템 개발</h4><i style="color:gray">제네시스랩</i><ul class="pt-2"><h5 id="--db------back-end--java-spring-boot-mariadb-redis-br-br-">담당 역할: DB 스키마 설계, 개발, 유지보수 등 Back-end 개발 (Java, Spring Boot, MariaDB, Redis) <br/><br/></h5><h5 id=""><strong>문제</strong></h5><li><span>AI Agent와의 유료 대화 기능 도입을 위한 신규 재화(&#x27;하트&#x27;) 관리 시스템의 부재 및 안정적인 결제/정산 기능 요구.</span></li><li><span>서비스 운영 중, 분산된 서버 환경(8대)에서 메시지큐를 통해 동일 유저의 재화 차감 요청이 동시 다발적으로 처리될 때, 재화가 정확히 차감되지 않는 데이터 불일치 현상(<strong style="font-weight:bold;:">동시성 이슈</strong>)을 발견했습니다. 이는 사용자 경험 및 서비스 신뢰도에 직접적인 영향을 미칠 수 있는 심각한 문제였습니다.</span></li><li><span><strong style="font-weight:bold;:">wrk를 이용한 부하 테스트</strong>를 통해 개발 환경에서 해당 동시성 문제를 재현하여, 트랜잭션 커밋 전 다른 요청이 이전 데이터를 조회하여 발생하는 &#x27;Lost Update&#x27;와 유사한 상황임을 명확히 했습니다.<br/><br/></span></li><h5 id="-br-"><strong>해결</strong><br/></h5><h6 id="redis---"><strong>[Redis 분산 락 도입]</strong></h6><li><span>데이터 정합성 확보를 위해 Redis 기반의 Redisson 분산 락(<code>tryLock</code>)을 도입했습니다.</span></li><li><span>Redisson의 Pub/Sub 메커니즘을 통해 성능 저하를 최소화하면서 안정적으로 <strong style="font-weight:bold;:">동시성을 제어</strong>했습니다.</span></li><li><span>이를 통해 결제/정산 시스템에서 요구되는 높은 수준의 데이터 정합성을 확보하는 실질적인 경험을 쌓았습니다. <br/><br/></span></li><h6 id="---"><strong>[부하 테스트를 통한 검증]</strong></h6><li><span>Redisson 분산 락 적용 전후로 <strong style="font-weight:bold;:">wrk</strong>를 사용하여 동일한 시나리오의 <strong style="font-weight:bold;:">부하 테스트</strong>를 재실시했습니다.</span></li><li><span>적용 후, 모든 요청이 순차적으로 처리되어 재화가 정확히 차감되는 것을 로그 및 데이터베이스 상태를 통해 정량적으로 검증하며 데이터 무결성 확보를 확인했습니다. <br/><br/></span></li><h6 id="---"><strong>[협업 및 지식 공유]</strong></h6><li><span>사업팀, 재무팀 등 유관부서와 긴밀히 소통하며 재화 정책을 수립하고 기술적 제약사항을 공유하여 효율적인 의사결정을 지원했습니다.</span></li><li><span>또한, 동시성 문제 해결 과정, Redisson 분산 락 적용 경험을 팀 내 기술 세미나 형식으로 공유하여 동료들의 분산 환경 문제 해결 역량 강화에 기여했습니다.</span></li><li><span><strong style="font-weight:bold;:">하단의 아티클 (동시성 이슈와 Redis Redisson를 이용한 해결방법, 동시성 제어를 위한 Redisson tryLock 메서드의 작동 원리)</strong> 이 팀 내 공유한 내용을 수정, 각색하여 포스팅한 블로그 글 입니다.<br/><br/></span></li><h5 id=""><strong>성과</strong></h5><li><span>AI 기반 유료 대화라는 신규 비즈니스 모델을 성공적으로 시장에 출시하고, 실제 운영 환경에서 발생한 치명적인 동시성 문제를 해결하여 안정적인 재화 운영 기반을 마련, 사용자 신뢰도 회복 및 서비스 활성화에 기여했습니다.</span></li><li><span>부하 테스트를 통한 검증으로 대규모 트래픽 환경에서도 신뢰할 수 있는 결제 및 재화 관리 시스템을 구축하여 서비스 안정성을 높이고, 사용자에게 긍정적인 경험을 제공했습니다.</span></li><li><span>팀 내 세미나와 기술 블로그를 통해 경험을 공유함으로써, 개인의 성장을 넘어 팀 전체의 기술적 성장에 기여하는 것에 보람을 느꼈습니다.</span></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2024. 07 ~ 2024. 08</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>ZUICY 사용자 리텐션 증대를 위한 AI 기반 선톡(先 Talk) 기능 개발</h4><i style="color:gray">제네시스랩</i><ul class="pt-2"><h5 id="------------java-spring-boot-mariadb-spring-scheduler-br-br-">담당 역할: 선톡 기능 기획 참여, 백엔드 시스템 설계 및 개발 주도 (Java, Spring Boot, MariaDB, Spring Scheduler) <br/><br/></h5><h5 id=""><strong>문제</strong></h5><li><span>서비스 주요 지표인 <strong style="font-weight:bold;:">사용자 리텐션 유지</strong>가 중요한 과제였으나, 한번 이탈한 사용자를 다시 서비스로 유입시킬 효과적인 장치가 부재했습니다.</span></li><li><span>하나의 정해신 시간에 <strong style="font-weight:bold;:">대규모 사용자 대상 개인화 메시지 발송 시</strong>, 메시지 생성(LLM API 호출) 및 실제 발송 과정에서 특정 시간대에 트래픽이 집중되어 시스템 성능 저하 및 LLM API 사용량 제한 초과가 우려되었습니다.</span></li><li><span>이로 인해 안정적이고 개인화된 메시지 발송에 어려움이 예상되었습니다.<br/><br/></span></li><h5 id="-br-"><strong>해결</strong><br/></h5><h6 id="------"><strong>[선톡 기능 핵심 로직 설계 및 구현]</strong></h6><li><span>AI 에이전트가 사용자에게 먼저 대화를 시작하는 &#x27;<strong style="font-weight:bold;:">선톡</strong>&#x27; 기능을 신규 개발하여, 사용자의 서비스 재참여를 적극적으로 유도했습니다.</span></li><li><span>유관부서와 협의하여 정책(예: 대상 유저, 발송 시간 등)을 수립 후 발송 대상자를 선정하고, 사용자의 이전 대화 내용을 기반으로 개인화된 메시지를 생성하는 <strong style="font-weight:bold;:">백엔드 시스템 전반을 설계하고 구현</strong>했습니다.<br/><br/></span></li><h6 id="llm-api----------"><strong>[LLM API 연동 및 대규모 메시지 생성/발송 최적화 전략 수립 및 실행]</strong></h6><li><span>사내 연구실에서 개발한 <strong style="font-weight:bold;:">LLM 기반 맞춤 메시지 생성 API</strong>를 활용하여 <strong style="font-weight:bold;:">일 10,000건 이상</strong>의 개인화된 선톡 메시지를 생성했습니다.</span></li><li><span>초기 접근 방식: 발송 시간 전에(예: 10~30분 전) 대상 유저를 조회하고 LLM API를 통해 실시간으로 메시지를 생성하려 했으나, 다음과 같은 문제점이 예상되었습니다.</span></li><ul><li><ol start="1"><li><strong style="font-weight:bold;:">LLM API(ChatGPT) 쿼터 제한</strong>으로 인한 메시지 생성 실패 및 발송 누락 가능성.</li></ol></li></ul><ul><li><ol start="2"><li>서버 부하 또는 LLM 응답 지연 시 <strong style="font-weight:bold;:">메시지 생성 지연</strong>으로 인한 적시 발송 실패 가능성.</li></ol></li></ul><li><span>개선된 접근 방식 (<strong style="font-weight:bold;:">선 생성 후 검증 발송</strong>): 위의 문제점을 해결하기 위해,</span></li><ul><li><ol start="1"><li>사용자 트래픽이 적은 시간대에 메시지를 미리 대량으로 생성해두고,</li></ol></li></ul><ul><li><ol start="2"><li>실제 발송 직전에 최종 발송 조건을 재확인하여 발송하는 방식으로 전략을 변경했습니다.</li></ol></li></ul><li><span>이 방식은 메시지를 미리 생성함으로써 일부 불필요한 자원(컴퓨팅 파워, LLM API 호출 비용 – 만약 사용자가 그 사이 재활성화된다면)이 소모될 수 있다는 단점이 있었지만, <strong style="font-weight:bold;:">안정적인 메시지 발송 성공률을 최우선</strong>으로 고려하여 <strong style="font-weight:bold;:">당시 상황에서의 최적</strong>의 해결책이라고 판단했습니다.<br/><br/></span></li><h6 id="spring-scheduler-----"><strong>[Spring Scheduler를 활용한 이중화된 자동화 프로세스 구축]</strong></h6><li><span>안정적인 선톡 기능 운영을 위해 총 2개의 Spring Scheduler를 구성하여 역할을 분담했습니다:</span></li><li><span>1. 메시지 생성 스케줄러: 매일 <strong style="font-weight:bold;:">사용자 트래픽이 가장 적은 시간대</strong>에 동작하여, 다음 날 발송될 후보 메시지들을 미리 생성하고 저장합니다.</span></li><li><span>2. 메시지 발송 스케줄러: 짧은 간격(예: 5분)으로 주기적으로 실행되며, 현재 시간에 발송해야 할 미리 생성된 메시지들을 조회하여 <strong style="font-weight:bold;:">최종 조건 검증 후 사용자에게 발송</strong>합니다.</span></li><li><span>이 <strong style="font-weight:bold;:">이중 스케줄러 구조</strong>를 통해 메시지 생성 부하와 발송 후 유저 트래픽을 효과적으로 분산시키고, LLM API 쿼터 문제 및 생성 지연으로 인한 발송 실패 가능성을 최소화하여 <strong style="font-weight:bold;:">시스템 안정성을 확보</strong>했습니다.<br/><br/></span></li><h6 id="----"><strong>[경험 공유 및 팀 협업]</strong></h6><li><span>해당 기능 개발 과정에서 얻은 <strong style="font-weight:bold;:">트래픽 분산 전략과 트레이드 오프 경험</strong>을 팀 내부에 공유하여 유사 기능 개발 중인 팀원들의 참고 자료로 활용되었습니다.</span></li><li><span>개발 과정에서 직면한 문제와 해결 방안을 정리하여 공유함으로써 <strong style="font-weight:bold;:">후속 프로젝트의 개발 효율성 향상에 기여</strong>했습니다.<br/><br/></span></li><h5 id=""><strong>성과</strong></h5><li><span>&#x27;<strong style="font-weight:bold;:">선톡</strong>&#x27; 기능의 성공적인 신규 개발을 통해 이탈 사용자의 <strong style="font-weight:bold;:">서비스 재참여율 40%를 달성</strong>하고 사용자 리텐션이 <strong style="font-weight:bold;:">10-20% 증가</strong>했습니다.</span></li><li><span><strong style="font-weight:bold;:">일 10,000건 이상</strong>의 개인화된 메시지를 안정적으로 생성 및 발송하는 시스템을 구축하여 대규모 메시징 처리 능력을 확보했습니다.</span></li><li><span><strong style="font-weight:bold;:">선 생성 후 검증 발송 전략</strong>과 <strong style="font-weight:bold;:">이중 Spring Scheduler 도입</strong>으로 시스템 부하 분산, LLM API 관련 문제 해결 및 <strong style="font-weight:bold;:">메시지 발송 성공률과 시스템 안정성을 크게 향상</strong>시켰습니다.</span></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2024. 06 ~ 2024. 08</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>ZUICY AI 챗봇 기능 개발 및 대규모 트래픽 처리 위한 시스템 개선</h4><i style="color:gray">제네시스랩</i><ul class="pt-2"><h5 id="--ai---------java-spring-boot-aws-sqs-webclient-br-br-">담당 역할: AI 챗봇 핵심 기능 개발 및 백엔드 아키텍처 개선 (Java, Spring Boot, AWS SQS, WebClient) <br/><br/></h5><h5 id=""><strong>문제</strong></h5><li><span>기존 영상 콘텐츠의 낮은 효율성으로 인해, 신규 사용자 유입 증대 및 리텐션 강화를 위한 핵심 기능으로 <strong style="font-weight:bold;:">AI 기반 대화 기능 도입이 시급</strong>했습니다.</span></li><li><span>기능 출시 후 사용자 수가 급증함에 따라 <strong style="font-weight:bold;:">채팅 응답 지연(최대 5분 이상)</strong>이 빈번하게 발생하여 사용자 경험이 심각하게 저하되었고, 이는 이탈률 증가로 이어질 수 있는 위험 요소였습니다.</span></li><li><span>기존 동기 방식 아키텍처는 외부 LLM API 응답 대기 시 <strong style="font-weight:bold;:">블로킹 이슈를 유발</strong>하여 스케일 아웃에 명확한 한계가 있었고, 대규모 동시 요청 처리에 어려움이 있었습니다.<br/><br/></span></li><h5 id="-br-"><strong>해결</strong><br/></h5><h6 id="1--------"><strong>[1단계: 병렬 스레드 처리를 통한 초기 응답 지연 완화]</strong></h6><li><span>문제의 핵심은 사내 LLM API 서버 호출 시 동기 방식으로 응답을 대기하며 발생하는 심각한 <strong style="font-weight:bold;:">병목 현상</strong>이었습니다.</span></li><li><span>LLM API 서버의 응답 지연이 채팅 서버의 전체 처리 속도 저하로 직결되었고, 이는 RDB에 채팅 결과를 업데이트하는 과정까지 지연시켰습니다.</span></li><li><span>이 문제를 일차적으로 완화하기 위해, Spring의 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">ThreadPoolTaskExecutor</code>와 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">CompletableFuture</code>를 활용하여 다수의 LLM API 요청을 <strong style="font-weight:bold;:">병렬 스레드로 동시에 전송하고 처리</strong>하도록 개선했습니다.</span></li><li><span>이를 통해 각 요청이 다른 요청의 LLM 응답 대기에 구애받지 않고 독립적으로 처리될 수 있도록 하여, 시스템 전체의 응답 대기 시간을 단축하고 초기 응답 지연 문제를 일부 해소했습니다.<br/><br/></span></li><h6 id="2--io----"><strong>[2단계: 비동기 I/O 도입으로 블로킹 이슈 해소]</strong></h6><li><span>LLM API 호출 시 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">RestTemplate</code>으로 인한 스레드 블로킹 문제를 근본적으로 해결하고자, 논블로킹 I/O를 지원하는 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">WebClient</code>로 전환했습니다.</span></li><li><span>이를 통해 시스템 자원 효율성을 높이고 동시 처리량을 증대시켜 응답 속도를 추가적으로 개선했습니다.<br/><br/></span></li><h6 id="3--sqs-----"><strong>[3단계: 메시지 큐(SQS) 기반 비동기 아키텍처로 전면 개편]</strong></h6><li><span>시스템 확장성과 안정성을 극대화하기 위해, 기존 채팅 서버를 채팅 요청 처리 서버와 채팅 응답 처리 서버로 분리하고, 두 서버와 LLM API 서버간의 통신을 <strong style="font-weight:bold;:">AWS SQS 기반의 완전 비동기 방식으로 전환</strong>했습니다.</span></li><li><span>이 아키텍처 변경을 통해 서버와 LLM API 서버 간의 의존성을 낮추고, 서버의 스케일아웃 및 장애 격리가 가능해져 <strong style="font-weight:bold;:">대규모 트래픽을 안정적으로 처리할 수 있는 기반</strong>을 마련했습니다.<br/><br/></span></li><h5 id=""><strong>성과</strong></h5><li><span>채팅 평균 응답 속도를 <strong style="font-weight:bold;:">분 단위에서 수 초 이내로 개선</strong>하여 심각한 서비스 장애 상황을 해결하고, 사용자 사용성을 크게 향상시켰습니다.</span></li><li><span>채팅 서버의 요청 처리량을 증가시키고 시스템 전반의 안정성을 확보하여, 향후 사용자 증가에도 유연하게 대응할 수 있는 <strong style="font-weight:bold;:">확장 가능한 시스템을 구축</strong>했습니다.</span></li><li><span>문제 해결 초기, LLM API 호출 병목 현상을 해결하기 위해 병렬처리가 아닌 동시성 처리가 필요함을 알았지만, 하지만 당시 해당 기술에 대한 숙련도가 충분하지 않아, 우선적으로 제가 더 익숙하게 다룰 수 있는 병렬 스레드 처리(<code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">ThreadPoolTaskExecutor</code>와 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">CompletableFuture</code>)를 통해 응답 지연을 완화하는 현실적인 접근을 선택했습니다.</span></li><li><span>이후 초기 응답속도 지연문제를 완화 후 WebClient 학습 및 도입(2단계), SQS 기반 완전 비동기 아키텍처 설계(3단계)로 나아가며 <strong style="font-weight:bold;:">문제 해결의 완성도를 높이고 기술 스펙트럼을 넓힐 수 있었습니다</strong>.</span></li><li><span>문제의 근본 원인을 분석하고 점진적인 해결책을 적용하여 확장 가능한 아키텍처로 발전시키는 전 과정에서 <strong style="font-weight:bold;:">주도적인 역할을 수행하며 시스템 전체를 보는 시각을 넓힐 수 있었습니다</strong>.</span></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2022. 11 ~ 2022. 11</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>웨딩의 여신 대규모 푸시 알림 시스템 성능 최적화</h4><i style="color:gray">유모멘트</i><ul class="pt-2"><h5 id="----------java-spring-boot----api--br-br-">담당 역할: 푸시 알림 시스템 성능 개선 및 백엔드 개발 (Java, Spring Boot, 외부 푸시 서비스 API 연동) <br/><br/></h5><h5 id="-"><strong>문제 정의</strong></h5><li><span>기존 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">@Scheduled</code> 기반 푸시 시스템은 단일 스레드로 푸시 요청을 1건씩 순차 처리하여, <strong style="font-weight:bold;:">19만 전체 사용자 대상 발송에 5시간 이상이 소요</strong>되는 심각한 성능 병목이 존재했습니다.</span></li><li><span>이로 인해 하루 1회 이상 푸시 발송이 현실적으로 불가능하여, 긴급 공지 전달 지연, <strong style="font-weight:bold;:">시의성이 중요한 마케팅 이벤트(예: 타임딜, 긴급 프로모션) 진행에 큰 제약</strong>이 따랐습니다.</span></li><li><span>결과적으로 마케팅 활동의 유연성이 크게 저하되고, 사용자에게 적시 정보를 전달하지 못해 <strong style="font-weight:bold;:">이벤트 참여율 저조 및 잠재적 사용자 불만을 야기</strong>할 수 있었습니다.<br/><br/></span></li><h5 id="-----br-"><strong>주요 해결 과정 및 기여</strong><br/></h5><h6 id="-----"><strong>[병렬 처리를 위한 스레드 풀 도입]</strong></h6><li><span>푸시 발송 작업의 병렬 처리를 위해, 푸시 전용 <code style="font-family:Consolas, monaco, monospace;background-color:#f5f5f5;padding:2px 4px;border-radius:4px;:">ThreadPoolTaskExecutor</code>(스레드 풀)를 도입하고 시스템 리소스를 고려하여 <strong style="font-weight:bold;:">최적의 스레드 수를 설정</strong>했습니다.</span></li><li><span>개별 푸시 발송 요청을 각각의 스레드에 할당하여 <strong style="font-weight:bold;:">동시에 다수의 푸시 알림을 전송할 수 있도록 기존 로직을 전면 수정</strong>했습니다.<br/><br/></span></li><h6 id="---api-----"><strong>[외부 푸시 서비스 API 벌크 발송 기능 적극 활용]</strong></h6><li><span>기존 시스템은 외부 푸시 서비스(카카오) API 호출 시 1건의 메시지만을 전송하는 비효율적인 구조였습니다.</span></li><li><span>외부 푸시 서비스의 API 문서를 면밀히 분석하여, 단일 API 호출로 <strong style="font-weight:bold;:">최대 100건의 메시지를 동시에 발송할 수 있는 벌크(Bulk) 발송 기능</strong>을 지원함을 확인했습니다.</span></li><li><span>이에, 사용자 목록을 100명 단위로 분할하고, 각 단위를 벌크 API를 통해 일괄 발송하도록 발송 로직을 개선하여 <strong style="font-weight:bold;:">API 호출 횟수를 획기적으로 줄였습니다</strong>.<br/><br/></span></li><h6 id="-----"><strong>[병렬 처리와 벌크 발송의 시너지 극대화]</strong></h6><li><span>병렬 스레드 처리와 푸시 API의 벌크 발송 기능을 결합하여, 각 스레드가 여러 건(최대 100건)의 메시지를 한 번의 API 호출로 처리하도록 함으로써 <strong style="font-weight:bold;:">시스템 처리량을 극대화</strong>했습니다.<br/><br/></span></li><h5 id="---"><strong>성과 및 배운 점</strong></h5><li><span>전체 사용자(19만 명) 대상 푸시 발송 시간을 기존 5시간 이상에서 <strong style="font-weight:bold;:">평균 30분 이내로 90% 이상 단축</strong>시켰습니다.</span></li><li><span>하루에도 여러 차례, 다양한 타겟 그룹을 대상으로 한 푸시 발송이 가능해져 <strong style="font-weight:bold;:">마케팅 캠페인 운영의 유연성과 효과가 크게 증대</strong>되었으며, 긴급 공지 등 중요 정보의 적시 전달이 가능해졌습니다.</span></li><li><span><strong style="font-weight:bold;:">외부 API의 제약사항 및 기능을 정확히 파악</strong>하고 이를 최대한 활용하여 시스템 성능을 최적화하는 것의 중요성을 깨달았습니다. 단순 로직 변경을 넘어, 외부 시스템과의 연동 방식 자체를 개선하는 것이 큰 성능 향상을 가져올 수 있음을 직접 경험했습니다.</span></li></ul></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2022. 07 ~ 2022. 08</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>웨딩의 여신 백엔드 공통 JPA Entity 모듈화</h4><i style="color:gray">웨딩의 여신</i><ul class="pt-2"><h5 id="---------java-jpa-spring-boot-mavengradle-nexus-repository-br-br-">담당 역할: 공통 모듈화 아키텍처 설계 및 개발 주도 (Java, JPA, Spring Boot, Maven/Gradle, Nexus Repository) <br/><br/></h5><h5 id="-"><strong>문제 정의</strong></h5><li><span>다수의 백엔드 서비스 프로젝트들이 동일한 데이터베이스를 공유함에도 불구하고, JPA Entity 클래스를 각 프로젝트별로 <strong style="font-weight:bold;:">중복 관리하여 코드 일관성 유지가 어려웠습니다</strong>.</span></li><li><span>Entity 스키마 변경 시, 관련된 모든 프로젝트의 코드를 개발자가 수동으로 찾아 일일이 수정해야 하는 <strong style="font-weight:bold;:">비효율적인 작업이 반복</strong>되었으며, 이는 상당한 개발 시간을 소모했습니다.</span></li><li><span>이러한 수동 동기화 과정은 <strong style="font-weight:bold;:">휴먼 에러 발생 가능성을 높여</strong> 프로젝트 간 데이터 모델 불일치를 초래했고, 중복 코드로 인한 전체적인 유지보수 비용 증가 및 개발 생산성 저하를 야기했습니다.<br/><br/></span></li><h5 id="-----br-"><strong>주요 해결 과정 및 기여</strong><br/></h5><h6 id="----"><strong>[공통 모듈 설계 및 분리]</strong></h6><li><span>여러 서비스 프로젝트에서 공통으로 사용되는 JPA Entity 클래스 및 관련 유틸리티 클래스들을 식별하여, 별도의 <strong style="font-weight:bold;:">&#x27;공통 데이터 모델&#x27; 프로젝트로 분리</strong>하는 작업을 주도했습니다.</span></li><li><span>모듈의 독립성과 재사용성을 고려하여 <strong style="font-weight:bold;:">명확한 의존성 경계를 설정</strong>했습니다.<br/><br/></span></li><h6 id="nexus-repository------"><strong>[Nexus Repository를 활용한 체계적인 배포 및 의존성 관리]</strong></h6><li><span>분리된 공통 모듈을 JAR 파일 형태로 빌드하여, 사내 <strong style="font-weight:bold;:">Nexus Maven Repository에 표준화된 방식으로 배포</strong>했습니다.</span></li><li><span>이를 통해 버전 관리의 체계성을 확보하고, 각 서비스 프로젝트에서 공통 모듈을 Maven/Gradle 의존성으로 손쉽게 추가하고 관리할 수 있도록 <strong style="font-weight:bold;:">인프라를 구축</strong>했습니다.<br/><br/></span></li><h6 id="------"><strong>[기존 서비스 프로젝트 리팩토링 및 전환 가이드]</strong></h6><li><span>기존 서비스 프로젝트들이 새로운 공통 모듈을 사용하도록 의존성을 변경하고, <strong style="font-weight:bold;:">관련 코드를 리팩토링</strong>하는 작업을 진행했습니다.</span></li><li><span>추후 다른 팀원들이 원활하게 전환할 수 있도록 <strong style="font-weight:bold;:">변경 가이드 문서를 작성하고 공유</strong>했습니다.<br/><br/></span></li><h5 id="---"><strong>성과 및 배운 점</strong></h5><li><span>공통 Entity 클래스 관리 포인트를 중앙화함으로써 <strong style="font-weight:bold;:">코드 중복을 완전히 제거</strong>하고, 모든 프로젝트에서 <strong style="font-weight:bold;:">데이터 모델의 일관성을 확보</strong>했습니다.</span></li><li><span>수동 코드 수정 및 동기화 과정을 원천적으로 제거함으로써 <strong style="font-weight:bold;:">휴먼 에러 발생 가능성을 차단</strong>하고, 데이터 모델의 정합성을 보장하여 <strong style="font-weight:bold;:">시스템 안정성을 높였습니다</strong>.</span></li><li><span>표준화된 공통 모듈 사용으로 신규 프로젝트 개발 시 Entity 관련 코드를 재작성할 필요가 없어져 개발 초기 세팅 시간을 단축하고 <strong style="font-weight:bold;:">전체적인 개발 생산성을 향상</strong>시켰습니다.</span></li><li><span>해당 과정에서 레이어간 분리를 명확히하여 이후 개발의 유지보수 및 생산성을 향상시킬 수 있었고, <strong style="font-weight:bold;:">프로젝트의 전반적인 아키텍처에 대해 고민</strong>해볼 수 있었습니다.</span></li></ul></div></div></div></div></div></div></div></div><div class="mt-5"><div class="row"><div class="col"><div class="pb-3 row"><div class="col"><h2 style="color:#3c78d8"><span>ARTICLE</span></h2></div></div><div class="row"><div class="col"><ul class=""><li><a href="https://jungguji.github.io/2025/01/09/%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%A0%9C%EC%96%B4%EB%A5%BC-%EC%9C%84%ED%95%9C-Redisson-tryLock-%EB%A9%94%EC%84%9C%EB%93%9C%EC%9D%98-%EC%9E%91%EB%8F%99-%EC%9B%90%EB%A6%AC" target="_blank" rel="noreferrer noopener">(2025. 01. 09) 동시성 제어를 위한 Redisson tryLock 메서드의 작동 원리</a></li><li><a href="https://jungguji.github.io/2024/12/24/%EB%8F%99%EC%8B%9C%EC%84%B1-%EC%9D%B4%EC%8A%88%EC%99%80-Redis-Redisson-%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95/" target="_blank" rel="noreferrer noopener">(2024. 12. 24) 동시성 이슈와 Redis( Redisson )를 이용한 해결방법</a></li><li><a href="https://jungguji.github.io/2024/11/19/%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%BD%94%EB%93%9C-%EC%9E%91%EC%84%B1%EC%9D%84-%EB%8D%94-%EC%89%BD%EA%B2%8C-with-Fixture-Monkey/" target="_blank" rel="noreferrer noopener">(2024. 11. 19) 테스트 코드 작성을 더 쉽게 (with. Fixture Monkey)</a></li><li><a href="https://jungguji.github.io/2022/08/07/Nexus%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%AA%A8%EB%93%88%ED%99%94/" target="_blank" rel="noreferrer noopener">(2022. 08. 07) Nexus를 이용한 모듈화</a></li></ul></div></div></div></div></div><div class="mt-5"><div class="row"><div class="col"><div class="pb-3 row"><div class="col"><h2><span style="color:#3c78d8">SKILL</span></h2></div></div><div><div class="row"><div class="text-md-right col-sm-12 col-md-3"><h4 style="color:gray">Back-end</h4></div><div class="col-sm-12 col-md-9"><div class="mt-2 mt-md-0 row"><div class="col-12 col-md-4"><ul><li>Java</li><li>Spring / Spring Boot</li></ul></div><div class="col-12 col-md-4"><ul><li>MySQL, MariaDB / Hibernate / Querydsl</li><li>Junit4 / 5</li></ul></div><div class="col-12 col-md-4"><ul><li>Maven, Gradle</li></ul></div></div></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><h4 style="color:gray">DevOps</h4></div><div class="col-sm-12 col-md-9"><div class="mt-2 mt-md-0 row"><div class="col-12 col-md-4"><ul><li>AWS EC2</li><li>AWS RDS</li></ul></div><div class="col-12 col-md-4"><ul><li>AWS S3</li><li>Linux Ubuntu</li></ul></div><div class="col-12 col-md-4"><ul></ul></div></div></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><h4 style="color:gray">Etc</h4></div><div class="col-sm-12 col-md-9"><div class="mt-2 mt-md-0 row"><div class="col-12 col-md-4"><ul><li>Git / Github / Bitbucket</li></ul></div><div class="col-12 col-md-4"><ul><li>Intelli J</li></ul></div><div class="col-12 col-md-4"><ul></ul></div></div></div></div></div></div></div></div><div class="mt-5"><div class="row"><div class="col"><div class="pb-3 row"><div class="col"><h2 style="color:#3c78d8"><span>EDUCATION</span></h2></div></div><div class="row"><div class="col"><div><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2017. 10 ~ 2018. 03</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>국가평생교육진흥원 학점은행제</h4><i style="color:gray">컴퓨터공학 전공(학사)</i></div></div></div><div><hr/><div class="row"><div class="text-md-right col-sm-12 col-md-3"><div class="row"><div class="col-md-12"><h4 style="color:gray">2012. 02 ~ 2017. 02</h4></div></div></div><div class="col-sm-12 col-md-9"><h4>경민대학교</h4><i style="color:gray">인터넷정보 전공(전문학사)</i></div></div></div></div></div></div></div></div><div class="row"><div style="background-color:#f5f5f5;padding-left:0;padding-right:0;margin-top:50px;height:80px" class="col"><div class="text-center mt-2"><div class="row"><div class="col"><small><a href="https://nextjs.org/" target="_blank" rel="noreferrer noopener">Next.js</a> v<!-- -->9.5.5<!-- --> / <!-- -->CSS by <a href="https://getbootstrap.com" target="_blank" rel="noreferrer noopener">Bootstrap</a> v<!-- -->4.6.2</small></div></div><div class="row"><div class="col"><small>v.<!-- -->2.0.0 / <a href="https://github.com/uyu423/resume-nextjs" target="_blank" rel="noreferrer noopener">Github</a> / <!-- -->Thanks for <a href="https://blog.outsider.ne.kr/1234" target="_blank" rel="noreferrer noopener">Outsider</a></small></div></div><br/></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/","query":{},"buildId":"UHFQwxwPPdVG5sh4nePRu","assetPrefix":"/resume","nextExport":true,"autoExport":true,"isFallback":false,"head":[["meta",{"name":"viewport","content":"width=device-width"}],["meta",{"charSet":"utf-8"}],["meta",{"name":"robots","content":"index,follow"}],["meta",{"name":"googlebot","content":"index,follow"}],["meta",{"property":"og:type","content":"profile"}],["meta",{"property":"profile:first_name","content":"Jung gu"}],["meta",{"property":"profile:last_name","content":"Ji"}],["meta",{"property":"profile:username","content":"junggu.ji.dev"}],["meta",{"property":"profile:gender","content":"male"}],["meta",{"property":"og:title","content":"지중구 이력서"}],["meta",{"property":"og:image","content":"/resume//_next/static/images/JGJI-ae4ee6ccb074598c4d1e4ad0fcd64dd6.jpg"}],["meta",{"property":"og:image:alt","content":"증명 사진"}],["meta",{"property":"og:image:width","content":"800"}],["meta",{"property":"og:image:height","content":"600"}],["title",{"children":"지중구 이력서"}],["link",{"rel":"shortcut icon","href":"/resume//_next/static/images/favicon-f8d15634f8502a47fbe53edeb125d982.ico"}]]}</script><script nomodule="" src="/resume/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/resume/_next/static/chunks/main-6c75bd467717b38043dc.js" async=""></script><script src="/resume/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/resume/_next/static/chunks/framework.53cfa66f9846f4090096.js" async=""></script><script src="/resume/_next/static/chunks/f4e18d47.2a1b3f92ee167813966f.js" async=""></script><script src="/resume/_next/static/chunks/f6078781a05fe1bcb0902d23dbbb2662c8d200b3.9ee6b060a042bf298ef6.js" async=""></script><script src="/resume/_next/static/chunks/pages/_app-f70cb09c4703462ce6b2.js" async=""></script><script src="/resume/_next/static/chunks/a9a7754c.1e1dd1aff4d8e69ede10.js" async=""></script><script src="/resume/_next/static/chunks/cb1608f2.004389bbd8c6c33791ed.js" async=""></script><script src="/resume/_next/static/chunks/0f1ac474.6861323f142ad29f5913.js" async=""></script><script src="/resume/_next/static/chunks/pages/index-3ed10d6fc154e8c60c10.js" async=""></script><script src="/resume/_next/static/UHFQwxwPPdVG5sh4nePRu/_buildManifest.js" async=""></script><script src="/resume/_next/static/UHFQwxwPPdVG5sh4nePRu/_ssgManifest.js" async=""></script></body></html>